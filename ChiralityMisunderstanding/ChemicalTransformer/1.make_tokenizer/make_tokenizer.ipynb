{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.features.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make SMILES tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "START = 1\n",
    "END = 2\n",
    "UNK = 3\n",
    "smiles_voc_set = [f'{i}' for i in range(10)]+['(', ')', '[', ']', ':', '=', '@', '@@', '+', '/', '\\\\', '.',\n",
    "    '-', '#', '%', 'c', 'i', 'o', 'n', 'p', 's', 'b',\n",
    "    'H', 'B', 'C', 'N', 'O', 'F', 'P', 'S', 'Cl', 'Br', 'I']\n",
    "\n",
    "voc2tok = {}\n",
    "voc2tok.update({'<pad>':PAD, '<s>':START, '</s>':END})\n",
    "voc2tok.update({voc:i+4 for i, voc in enumerate(smiles_voc_set)})\n",
    "\n",
    "n_voc = max([tok for tok in voc2tok.values()])+1\n",
    "tok2voc = np.ndarray(n_voc, dtype='<U5')\n",
    "for voc, tok in voc2tok.items():\n",
    "    tok2voc[tok] = voc\n",
    "tok2voc[UNK] = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokenizer = Tokenizer(tok2voc, PAD, START, END, UNK, 2)\n",
    "with open(\"smiles_tokenizer.pkl\", mode='wb') as f:\n",
    "    pickle.dump(smiles_tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tokenizer for both SMILES and InChI (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchi_smiles_vocs = \\\n",
    "    ['<pad>', '<s>', '</s>', 'unk']\\\n",
    "    +[str(i) for i in range(10)]\\\n",
    "    +['(', ')', '[', ']', ':', '=', '@', '@@', '+', '/', '\\\\', '.', ',', '?',\n",
    "    '-', '#', '%', 'c', 'i', 'o', 'n', 'p', 's', 'b', 'l', 'h', 't', 'q', 'm',\n",
    "    'H', 'B', 'C', 'N', 'O', 'F', 'P', 'S', 'Cl', 'Br', 'I']\n",
    "\n",
    "inchi_smiles_tokenizer = Tokenizer(inchi_smiles_vocs, PAD, START, END, UNK, 2)\n",
    "with open(\"inchi_smiles_tokenizer.pkl\", mode='wb') as f:\n",
    "    pickle.dump(inchi_smiles_tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe55f37966b3abd9a1c897e1ad48e5b020177d57466134a7581b36d84c16101f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('torch-field': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}